{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries & Load Dataframe from AWS DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:34:28.450037Z",
     "start_time": "2020-01-21T19:34:26.963869Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "import query_helper\n",
    "import get_new_route\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:34:29.033243Z",
     "start_time": "2020-01-21T19:34:28.492956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>stars</th>\n",
       "      <th>starVotes</th>\n",
       "      <th>pitches</th>\n",
       "      <th>location</th>\n",
       "      <th>region</th>\n",
       "      <th>area</th>\n",
       "      <th>sub_area</th>\n",
       "      <th>wall</th>\n",
       "      <th>...</th>\n",
       "      <th>run out</th>\n",
       "      <th>well protected</th>\n",
       "      <th>chimney</th>\n",
       "      <th>offwidth</th>\n",
       "      <th>stem</th>\n",
       "      <th>arete</th>\n",
       "      <th>crimp</th>\n",
       "      <th>vertical</th>\n",
       "      <th>powerful</th>\n",
       "      <th>in_range</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105714722</th>\n",
       "      <td>Central Yellow Wall</td>\n",
       "      <td>V3 R</td>\n",
       "      <td>4.4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>Custer State Park</td>\n",
       "      <td>Sylvan Lake</td>\n",
       "      <td>Sylvan Lake Bouldering</td>\n",
       "      <td>Campground Boulder</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105714728</th>\n",
       "      <td>Waves</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>217</td>\n",
       "      <td>2</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>The Needles Of Rushmore</td>\n",
       "      <td>Mount Rushmore National Memorial</td>\n",
       "      <td>South Seas</td>\n",
       "      <td>Shipyard Rock</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105714731</th>\n",
       "      <td>East Chimney Variation</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>Custer State Park</td>\n",
       "      <td>Cathedral Spires</td>\n",
       "      <td>Station 13</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105714734</th>\n",
       "      <td>Conn Diagonal</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>151</td>\n",
       "      <td>3</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>Custer State Park</td>\n",
       "      <td>Sylvan Lake</td>\n",
       "      <td>Outlets</td>\n",
       "      <td>Outer Outlet</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105714737</th>\n",
       "      <td>Bolts for Bobs</td>\n",
       "      <td>5.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>The Needles Of Rushmore</td>\n",
       "      <td>Mount Rushmore National Memorial</td>\n",
       "      <td>South Seas</td>\n",
       "      <td>Borneo</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name rating  stars  starVotes  pitches  \\\n",
       "id                                                                    \n",
       "105714722     Central Yellow Wall   V3 R    4.4         22        0   \n",
       "105714728                   Waves    5.8    4.6        217        2   \n",
       "105714731  East Chimney Variation    5.7    4.1         40        2   \n",
       "105714734           Conn Diagonal    5.7    4.9        151        3   \n",
       "105714737          Bolts for Bobs    5.8    3.5        125        1   \n",
       "\n",
       "               location                   region  \\\n",
       "id                                                 \n",
       "105714722  South Dakota        Custer State Park   \n",
       "105714728  South Dakota  The Needles Of Rushmore   \n",
       "105714731  South Dakota        Custer State Park   \n",
       "105714734  South Dakota        Custer State Park   \n",
       "105714737  South Dakota  The Needles Of Rushmore   \n",
       "\n",
       "                                       area                sub_area  \\\n",
       "id                                                                    \n",
       "105714722                       Sylvan Lake  Sylvan Lake Bouldering   \n",
       "105714728  Mount Rushmore National Memorial              South Seas   \n",
       "105714731                  Cathedral Spires              Station 13   \n",
       "105714734                       Sylvan Lake                 Outlets   \n",
       "105714737  Mount Rushmore National Memorial              South Seas   \n",
       "\n",
       "                         wall  ...  run out  well protected chimney  offwidth  \\\n",
       "id                             ...                                              \n",
       "105714722  Campground Boulder  ...        0               0       0         0   \n",
       "105714728       Shipyard Rock  ...        0               0       0         0   \n",
       "105714731                   0  ...        0               0       0         0   \n",
       "105714734        Outer Outlet  ...        0               0       0         0   \n",
       "105714737              Borneo  ...        0               0       0         0   \n",
       "\n",
       "           stem  arete  crimp  vertical  powerful  in_range  \n",
       "id                                                           \n",
       "105714722     0      0      0         0         0         1  \n",
       "105714728     0      0      0         1         0         1  \n",
       "105714731     0      0      0         0         0         1  \n",
       "105714734     1      0      0         0         0         1  \n",
       "105714737     0      0      0         0         0         1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numeric = pd.read_csv('df.csv', index_col='id')\n",
    "#reorder columns\n",
    "df_numeric =df_numeric[['name', 'rating', 'stars', 'starVotes', 'pitches', 'location', 'region',\n",
    "                               'area', 'sub_area', 'wall', 'longitude', 'latitude', 'url', 'Sport',\n",
    "                               'Trad', 'Boulder', 'TR', 'Alpine', 'Aid', 'Ice', 'Snow', 'Mixed',\n",
    "                               'danger', 'rope_grade', 'boulder_grade', 'infos', 'slab', 'traverse',\n",
    "                               'roof', 'corner', 'crack', 'face', 'flake', 'fingers', 'jug', 'exposed',\n",
    "                               'dihedral', 'sustained', 'technical', 'run out', 'well protected',\n",
    "                               'chimney', 'offwidth', 'stem', 'arete', 'crimp', 'vertical', 'powerful',\n",
    "                               'in_range']]\n",
    "df_numeric.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get input from user for recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:34:29.247678Z",
     "start_time": "2020-01-21T19:34:29.244898Z"
    }
   },
   "outputs": [],
   "source": [
    "target_id = 106875741\n",
    "# target_lat = 32.9127 \n",
    "# target_lon = -116.882\n",
    "target_state =''\n",
    "target_city =''\n",
    "target_zipcode = '92008'\n",
    "target_radius_range=60\n",
    "star_limit = 3.5\n",
    "###other parameters to be added here later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T20:22:32.477122Z",
     "start_time": "2020-01-21T20:22:32.473061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type('ss') == str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get coordinates for zip or city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:05:35.441987Z",
     "start_time": "2020-01-21T19:05:35.003559Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('us-zip-code-latitude-and-longitude.json') as f:\n",
    "  coord_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:05:37.177225Z",
     "start_time": "2020-01-21T19:05:37.172957Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_coords(target_city=None, target_state=None, zipcode=None):\n",
    "    #find the coordinates for city or zip code\n",
    "    for city in coord_dict:\n",
    "        if city['fields']['zip']==zipcode:\n",
    "            return city['fields']['latitude'],city['fields']['longitude']\n",
    "        if (city['fields']['state']==target_state)&(city['fields']['city']==target_city):\n",
    "            return city['fields']['latitude'],city['fields']['longitude']\n",
    "    #if nothing is found return none\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:05:38.889250Z",
     "start_time": "2020-01-21T19:05:38.882466Z"
    }
   },
   "outputs": [],
   "source": [
    "target_lat, target_lon = get_coords(target_city, target_state, target_zipcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:05:40.580456Z",
     "start_time": "2020-01-21T19:05:40.577734Z"
    }
   },
   "outputs": [],
   "source": [
    "print(target_lat, target_lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create fxn to see if climb is in search range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:05:51.835828Z",
     "start_time": "2020-01-21T19:05:51.828765Z"
    }
   },
   "outputs": [],
   "source": [
    "#function takes search param range and assigns to original df if climb in_range\n",
    "def in_range(df_fxn, lat, lon, radius_range=None):\n",
    "    if radius_range:\n",
    "        R= 3958.8 \n",
    "        if (lat == None)|(lon==None):\n",
    "            df_fxn['in_range'] = 1\n",
    "        else:\n",
    "            #assign target coords and set to radians for calc\n",
    "            lat1 = radians(lat)\n",
    "            lon1 = radians(lon)\n",
    "            for index, row in df_fxn.iterrows():\n",
    "                #assign the lat and lon for each climb\n",
    "                lat2 = radians(row['latitude'])\n",
    "                lon2 = radians(row['longitude'])\n",
    "\n",
    "                dlon = lon2 - lon1\n",
    "                dlat = lat2 - lat1\n",
    "\n",
    "                a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "                c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "                distance = R * c\n",
    "\n",
    "                #assign in_range col to 1 if the climb is in range\n",
    "                if distance < radius_range:\n",
    "                    df_fxn.at[index,'in_range']=1\n",
    "                else:\n",
    "                    df_fxn.at[index,'in_range']=0   \n",
    "    else:\n",
    "        df_fxn['in_range'] =1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:05:53.641578Z",
     "start_time": "2020-01-21T19:05:53.638369Z"
    }
   },
   "outputs": [],
   "source": [
    "def star_cutoff(df_fxn, star_limit=3.5):\n",
    "    for index, row in df_fxn.iterrows():\n",
    "        #assign in_range col to 1 if the climb is in range\n",
    "        if (df_fxn.at[index, 'stars'] >= star_limit)&(df_fxn.at[index, 'in_range']!=0):\n",
    "            df_fxn.at[index,'in_range']=1\n",
    "        else:\n",
    "            df_fxn.at[index,'in_range']=0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:07:30.243351Z",
     "start_time": "2020-01-21T19:07:30.237222Z"
    }
   },
   "outputs": [],
   "source": [
    "df_numeric.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:05:55.307033Z",
     "start_time": "2020-01-21T19:05:55.301482Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_numeric.loc[target_id,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T18:54:27.798322Z",
     "start_time": "2020-01-21T18:54:21.349Z"
    }
   },
   "outputs": [],
   "source": [
    "# ##difficulity cutoff, function not run until climb is in df\n",
    "# def diff_cutoff(df_fxn, delta=6, target_grade):\n",
    "#     if df_fxn.loc[target_id,'Boulder']==0:\n",
    "#         target_grade = df_fxn.loc[target_id,'rope_grade']\n",
    "#         for index, row in df_fxn.iterrows():\n",
    "#             #assign in_range col to 1 if the climb is in range\n",
    "#             if (df_fxn.at[index, 'rope_grade'] <= target_grade+delta)&(df_fxn.at[index, 'rope_grade'] >= target_grade-delta)\n",
    "#                 &(df_fxn.at[index, 'in_range']!=0):\n",
    "#                 df_fxn.at[index,'in_range']=1\n",
    "#             else:\n",
    "#                 df_fxn.at[index,'in_range']=0                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call function to assign if climb in range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T18:54:27.806260Z",
     "start_time": "2020-01-21T18:54:24.021Z"
    }
   },
   "outputs": [],
   "source": [
    "## used to get list of climbs allowed for comparison\n",
    "in_range(df_numeric, lat = target_lat, lon = target_lon, radius_range=target_radius_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Star cutoff (ie only give results for routes with above 3.5 stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T18:52:03.216792Z",
     "start_time": "2020-01-20T18:52:00.326542Z"
    }
   },
   "outputs": [],
   "source": [
    "star_cutoff(df_numeric, star_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T18:52:03.775942Z",
     "start_time": "2020-01-20T18:52:03.770574Z"
    }
   },
   "outputs": [],
   "source": [
    "df_numeric.in_range.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To begin, see if if the climb already exists in db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T21:32:33.031278Z",
     "start_time": "2020-01-21T21:32:33.022171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have climb already\n"
     ]
    }
   ],
   "source": [
    "if target_id in df_numeric.index:\n",
    "    print('We have climb already')\n",
    "    #make sure reference climb is assigned in_range\n",
    "    df_numeric.loc[target_id,'in_range']=1\n",
    "else:\n",
    "    print('Making API call and Scraping climb data')\n",
    "    if(get_new_route.get_route_details(target_id)):\n",
    "        #the function in the if statement saves target climb to target_climb.csv and returns 1\n",
    "        df_target= pd.read_csv('target_climb.csv', index_col= 'id')\n",
    "        df_target.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "        df_target['in_range'] = 1\n",
    "        #order the same as df_numeric columns\n",
    "        df_target = df_target[['name', 'rating', 'stars', 'starVotes', 'pitches', 'location', 'region',\n",
    "                               'area', 'sub_area', 'wall', 'longitude', 'latitude', 'url', 'Sport',\n",
    "                               'Trad', 'Boulder', 'TR', 'Alpine', 'Aid', 'Ice', 'Snow', 'Mixed',\n",
    "                               'danger', 'rope_grade', 'boulder_grade', 'infos', 'slab', 'traverse',\n",
    "                               'roof', 'corner', 'crack', 'face', 'flake', 'fingers', 'jug', 'exposed',\n",
    "                               'dihedral', 'sustained', 'technical', 'run out', 'well protected',\n",
    "                               'chimney', 'offwidth', 'stem', 'arete', 'crimp', 'vertical', 'powerful',\n",
    "                               'in_range']]\n",
    "        \n",
    "        df_numeric = pd.concat([df_numeric, df_target])\n",
    "    else:\n",
    "        print(\"Something went wrong\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T21:32:08.627393Z",
     "start_time": "2020-01-21T21:32:08.621639Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                                                    Via Leni 6b\n",
       "rating                                                        5.10b\n",
       "stars                                                             5\n",
       "starVotes                                                         4\n",
       "pitches                                                           6\n",
       "location                                              International\n",
       "region                                                       Europe\n",
       "area                                                    Switzerland\n",
       "sub_area                                             Albigna Valley\n",
       "wall                                                 Spazzacaldeira\n",
       "longitude                                                    9.6383\n",
       "latitude                                                    46.3387\n",
       "url               https://www.mountainproject.com/route/10687574...\n",
       "Sport                                                             1\n",
       "Trad                                                              0\n",
       "Boulder                                                           0\n",
       "TR                                                                0\n",
       "Alpine                                                            1\n",
       "Aid                                                               0\n",
       "Ice                                                               0\n",
       "Snow                                                              0\n",
       "Mixed                                                             0\n",
       "danger                                                            0\n",
       "rope_grade                                                       22\n",
       "boulder_grade                                                     0\n",
       "infos                                                           NaN\n",
       "slab                                                              0\n",
       "traverse                                                          0\n",
       "roof                                                              0\n",
       "corner                                                            0\n",
       "crack                                                             0\n",
       "face                                                              0\n",
       "flake                                                             0\n",
       "fingers                                                           0\n",
       "jug                                                               0\n",
       "exposed                                                           0\n",
       "dihedral                                                          0\n",
       "sustained                                                         0\n",
       "technical                                                         0\n",
       "run out                                                           0\n",
       "well protected                                                    0\n",
       "chimney                                                           0\n",
       "offwidth                                                          0\n",
       "stem                                                              0\n",
       "arete                                                             0\n",
       "crimp                                                             0\n",
       "vertical                                                          0\n",
       "powerful                                                          0\n",
       "in_range                                                          1\n",
       "Name: 106875741, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numeric.loc[target_id,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T21:31:40.227087Z",
     "start_time": "2020-01-21T21:31:40.208396Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>stars</th>\n",
       "      <th>starVotes</th>\n",
       "      <th>pitches</th>\n",
       "      <th>location</th>\n",
       "      <th>region</th>\n",
       "      <th>area</th>\n",
       "      <th>sub_area</th>\n",
       "      <th>wall</th>\n",
       "      <th>...</th>\n",
       "      <th>run out</th>\n",
       "      <th>well protected</th>\n",
       "      <th>chimney</th>\n",
       "      <th>offwidth</th>\n",
       "      <th>stem</th>\n",
       "      <th>arete</th>\n",
       "      <th>crimp</th>\n",
       "      <th>vertical</th>\n",
       "      <th>powerful</th>\n",
       "      <th>in_range</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118210398</th>\n",
       "      <td>Dead and Bloated</td>\n",
       "      <td>V5-6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "      <td>Southern Sierra</td>\n",
       "      <td>San Joaquin River Gorge</td>\n",
       "      <td>Downstream</td>\n",
       "      <td>Dead and Bloated Boulder</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118210488</th>\n",
       "      <td>Unknown #1</td>\n",
       "      <td>V0-1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "      <td>Lake Tahoe</td>\n",
       "      <td>I-80 Corridor</td>\n",
       "      <td>Auburn and Grass Valley</td>\n",
       "      <td>Auburn SRA,Tall Green Bridge,Riverside Boulder...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118210496</th>\n",
       "      <td>Unknown #2</td>\n",
       "      <td>V1-2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "      <td>Lake Tahoe</td>\n",
       "      <td>I-80 Corridor</td>\n",
       "      <td>Auburn and Grass Valley</td>\n",
       "      <td>Auburn SRA,Tall Green Bridge,Riverside Boulder...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118210504</th>\n",
       "      <td>Unknown #3</td>\n",
       "      <td>V1-2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "      <td>Lake Tahoe</td>\n",
       "      <td>I-80 Corridor</td>\n",
       "      <td>Auburn and Grass Valley</td>\n",
       "      <td>Auburn SRA,Tall Green Bridge,Riverside Boulder...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118211517</th>\n",
       "      <td>Mertensia Pillar</td>\n",
       "      <td>WI5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>CO Ice &amp; Mixed</td>\n",
       "      <td>RMNP - Mixed/Ice</td>\n",
       "      <td>Wild Basin</td>\n",
       "      <td>Mertensia Falls</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name rating  stars  starVotes  pitches    location  \\\n",
       "id                                                                          \n",
       "118210398  Dead and Bloated   V5-6    5.0          1        0  California   \n",
       "118210488        Unknown #1   V0-1    3.0          1        0  California   \n",
       "118210496        Unknown #2   V1-2    3.0          1        0  California   \n",
       "118210504        Unknown #3   V1-2    3.0          1        0  California   \n",
       "118211517  Mertensia Pillar    WI5    4.0          1        1    Colorado   \n",
       "\n",
       "                    region                     area                 sub_area  \\\n",
       "id                                                                             \n",
       "118210398  Southern Sierra  San Joaquin River Gorge               Downstream   \n",
       "118210488       Lake Tahoe            I-80 Corridor  Auburn and Grass Valley   \n",
       "118210496       Lake Tahoe            I-80 Corridor  Auburn and Grass Valley   \n",
       "118210504       Lake Tahoe            I-80 Corridor  Auburn and Grass Valley   \n",
       "118211517   CO Ice & Mixed         RMNP - Mixed/Ice               Wild Basin   \n",
       "\n",
       "                                                        wall  ...  run out  \\\n",
       "id                                                            ...            \n",
       "118210398                           Dead and Bloated Boulder  ...        0   \n",
       "118210488  Auburn SRA,Tall Green Bridge,Riverside Boulder...  ...        0   \n",
       "118210496  Auburn SRA,Tall Green Bridge,Riverside Boulder...  ...        0   \n",
       "118210504  Auburn SRA,Tall Green Bridge,Riverside Boulder...  ...        0   \n",
       "118211517                                    Mertensia Falls  ...        0   \n",
       "\n",
       "           well protected chimney  offwidth  stem  arete  crimp  vertical  \\\n",
       "id                                                                          \n",
       "118210398               0       0         0     0      0      0         0   \n",
       "118210488               0       0         0     0      0      0         0   \n",
       "118210496               0       0         0     0      0      0         0   \n",
       "118210504               0       0         0     0      1      0         0   \n",
       "118211517               0       0         0     0      0      0         0   \n",
       "\n",
       "           powerful  in_range  \n",
       "id                             \n",
       "118210398         0         1  \n",
       "118210488         0         1  \n",
       "118210496         0         1  \n",
       "118210504         0         1  \n",
       "118211517         0         1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numeric.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Diff_grade cutoff WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T19:49:31.837415Z",
     "start_time": "2020-01-20T19:49:31.835374Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "###WIP call grade range function\n",
    "# pass in deets for target climb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reccomender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Kernel Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T18:57:16.359716Z",
     "start_time": "2020-01-20T18:57:16.332874Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Import kernels\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import polynomial_kernel\n",
    "from sklearn.metrics.pairwise import sigmoid_kernel\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.metrics.pairwise import laplacian_kernel\n",
    "from sklearn.metrics.pairwise import chi2_kernel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T18:57:16.987774Z",
     "start_time": "2020-01-20T18:57:16.985268Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create df_in_range to run recommender in subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T20:55:43.929724Z",
     "start_time": "2020-01-21T20:55:43.863270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36614, 50)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_range = df_numeric[df_numeric['in_range']==1].reset_index()      \n",
    "target_index =df_in_range.index[df_in_range['id']==target_id][0] #store target climb index in subset that will be compared\n",
    "df_in_range.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T20:56:41.259761Z",
     "start_time": "2020-01-21T20:56:41.253933Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "5        False\n",
       "6        False\n",
       "7        False\n",
       "8        False\n",
       "9        False\n",
       "10       False\n",
       "11       False\n",
       "12       False\n",
       "13       False\n",
       "14       False\n",
       "15       False\n",
       "16       False\n",
       "17       False\n",
       "18       False\n",
       "19       False\n",
       "20       False\n",
       "21       False\n",
       "22       False\n",
       "23       False\n",
       "24       False\n",
       "25       False\n",
       "26       False\n",
       "27       False\n",
       "28       False\n",
       "29       False\n",
       "         ...  \n",
       "36584    False\n",
       "36585    False\n",
       "36586    False\n",
       "36587    False\n",
       "36588    False\n",
       "36589    False\n",
       "36590    False\n",
       "36591    False\n",
       "36592    False\n",
       "36593    False\n",
       "36594    False\n",
       "36595    False\n",
       "36596    False\n",
       "36597    False\n",
       "36598    False\n",
       "36599    False\n",
       "36600    False\n",
       "36601    False\n",
       "36602    False\n",
       "36603    False\n",
       "36604    False\n",
       "36605    False\n",
       "36606    False\n",
       "36607    False\n",
       "36608    False\n",
       "36609    False\n",
       "36610    False\n",
       "36611    False\n",
       "36612    False\n",
       "36613    False\n",
       "Name: id, Length: 36614, dtype: bool"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_range['id']==target_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T20:59:06.725202Z",
     "start_time": "2020-01-21T20:59:06.720552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([13471], dtype='int64')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_range.index[df_in_range['id']==target_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T18:58:23.107180Z",
     "start_time": "2020-01-20T18:58:23.104031Z"
    }
   },
   "outputs": [],
   "source": [
    "target_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T18:58:23.942591Z",
     "start_time": "2020-01-20T18:58:23.925293Z"
    }
   },
   "outputs": [],
   "source": [
    "df_in_range.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Features DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T19:54:10.365021Z",
     "start_time": "2020-01-20T19:54:10.359876Z"
    }
   },
   "outputs": [],
   "source": [
    "#creates features from df_in_range used for comparison\n",
    "features = df_in_range.loc[:,['stars', 'pitches', 'Sport', 'Trad', 'Boulder', 'TR', 'Alpine', 'Aid',\n",
    "       'Ice', 'Snow', 'Mixed', 'danger', 'rope_grade', 'boulder_grade', 'slab', 'traverse', 'roof', \n",
    "                'corner', 'crack', 'face','flake', 'fingers',\n",
    "                 'jug', 'exposed', 'dihedral', 'sustained', 'technical','run out', 'well protected',\n",
    "                 'chimney', 'offwidth', 'stem', 'arete','crimp', 'vertical', 'powerful']] #,'longitude','latitude',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T19:54:11.129226Z",
     "start_time": "2020-01-20T19:54:11.125186Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T19:54:16.828810Z",
     "start_time": "2020-01-20T19:54:16.826840Z"
    }
   },
   "outputs": [],
   "source": [
    "# features.iloc[:,[12,13]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick scaling type (AND UPDATE WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T18:58:51.964456Z",
     "start_time": "2020-01-20T18:58:51.962042Z"
    }
   },
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "scalar = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T19:48:23.240111Z",
     "start_time": "2020-01-20T19:48:23.230369Z"
    }
   },
   "outputs": [],
   "source": [
    "##### Pick a scaling option ###############################\n",
    "\n",
    "# features_scaled = scalar.fit_transform(features)\n",
    "# features_scaled = min_max_scaler.fit_transform(features.drop(columns=['danger','pitches']))\n",
    "\n",
    "features_scaled = min_max_scaler.fit_transform(features)\n",
    "\n",
    "# scale danger and pitches using ss and add into features scaled df\n",
    "# features_scaled = np.concatenate((features_scaled, scalar.fit_transform(features[['danger', 'pitches']])), axis=1)\n",
    "\n",
    "##################################################################\n",
    "\n",
    "for i in range(features_scaled.shape[0]):\n",
    "    features_scaled[i][10]=features_scaled[i][12]*10  #weight rope_grade higher\n",
    "    features_scaled[i][11]=features_scaled[i][13]*10 #weight boulder_grade higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets fit the similarity model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rec function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T18:59:53.537140Z",
     "start_time": "2020-01-20T18:59:53.531408Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_recommendations(idx, kernel_type):\n",
    "\n",
    "    #value to store scores and indicies\n",
    "    score_matrix = np.ndarray(shape=(len(df_in_range),2), dtype=float)\n",
    "\n",
    "    #go through the target climb vs all onthers in our db and populate score mtx with index and similarity\n",
    "    for i in range(df_in_range.shape[0]):\n",
    "        score = kernel_type(features_scaled[idx].reshape(1,-1),features_scaled[i].reshape(1,-1))\n",
    "        score_matrix[i][0] =  i        ##the index comparison corresponding to the score\n",
    "        score_matrix[i][1] = score     ##the score for the current index\n",
    "\n",
    "    # Sort the climbs based on the similarity scores\n",
    "    score_matrix = sorted(score_matrix, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "\n",
    "#########################  WIP ADD/calculate SIMilarity VALUE from tf-idf infos comparison #######################\n",
    "\n",
    "    # # Get the scores of the 20 most similar climbs\n",
    "    score_matrix = score_matrix[1:11]\n",
    "\n",
    "    # # Get the climb indices (& cast to ints)\n",
    "    climb_indices = [int(i[0]) for i in score_matrix]\n",
    "    \n",
    "    # Return the top 20 most similar climbs\n",
    "    return df_in_range.loc[climb_indices,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cells for comparison (delete later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T19:03:06.146302Z",
     "start_time": "2020-01-20T19:03:06.141141Z"
    }
   },
   "outputs": [],
   "source": [
    "df_numeric.loc[target_id, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T19:03:06.847952Z",
     "start_time": "2020-01-20T19:03:06.845054Z"
    }
   },
   "outputs": [],
   "source": [
    "target_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call rec fxn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T19:03:45.443350Z",
     "start_time": "2020-01-20T19:03:45.440979Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns= 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T19:54:47.055927Z",
     "start_time": "2020-01-20T19:54:46.788592Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rec=get_recommendations(target_index, cosine_similarity)\n",
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T19:54:49.610283Z",
     "start_time": "2020-01-20T19:54:49.380867Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rec=get_recommendations(target_index, rbf_kernel)\n",
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T19:03:49.445134Z",
     "start_time": "2020-01-20T19:03:49.228855Z"
    }
   },
   "outputs": [],
   "source": [
    "rec=get_recommendations(target_index, laplacian_kernel)\n",
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T19:55:27.247275Z",
     "start_time": "2020-01-20T19:55:27.245160Z"
    }
   },
   "outputs": [],
   "source": [
    "# rec=get_recommendations(target_index, euclidean_distances)\n",
    "# rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T19:55:28.044734Z",
     "start_time": "2020-01-20T19:55:28.042276Z"
    }
   },
   "outputs": [],
   "source": [
    "# rec=get_recommendations(target_index, linear_kernel)\n",
    "# rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T19:55:28.713949Z",
     "start_time": "2020-01-20T19:55:28.711590Z"
    }
   },
   "outputs": [],
   "source": [
    "# rec=get_recommendations(target_index, polynomial_kernel)\n",
    "# rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T19:55:29.384012Z",
     "start_time": "2020-01-20T19:55:29.382299Z"
    }
   },
   "outputs": [],
   "source": [
    "# rec=get_recommendations(target_index, sigmoid_kernel)\n",
    "# rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T19:55:30.059805Z",
     "start_time": "2020-01-20T19:55:30.057957Z"
    }
   },
   "outputs": [],
   "source": [
    "# rec=get_recommendations(climb_id, chi2_kernel)\n",
    "# rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## NLP (work in progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Import NLP Data (redundent delete later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T19:13:20.299633Z",
     "start_time": "2020-01-21T19:13:18.121878Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_nlp = query_helper.query_to_df('SELECT * FROM route_description;')\n",
    "df_nlp.set_index('id', inplace=True)\n",
    "df_nlp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "key_words = ['slab', 'traverse', 'roof', 'corner', 'ledge', 'crack', 'face','flake', 'finger', 'fingers',\n",
    "             'hand', 'hands', 'arch', 'balancy', 'balance', 'jug', 'squeeze', 'mantel', 'sustained',  \n",
    "             'ramp', 'overhung', 'dihedral', 'sporty', 'heady', 'pump', 'pumpy', 'technical',\n",
    "             'run out', 'mental', 'well protected', 'chimney', 'offwidth', 'stem', 'arete', 'exposed', 'exposure',\n",
    "             'crimp','crimpy', 'vertical', 'slabby', 'cave', 'steep', 'bouldery'. 'powerful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T19:29:11.530067Z",
     "start_time": "2020-01-14T19:29:11.526644Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "col_key_words = ['slab', 'traverse', 'roof', 'corner', 'ledge', 'crack', 'face','flake', 'finger',\n",
    "             'hand', 'arch', 'balancy', 'jug', 'squeeze', 'mantel', 'exposed', \n",
    "             'ramp', 'overhung', 'dihedral', 'sporty', 'sustained','pump', 'technical',\n",
    "             'run out', 'mental', 'well protected', 'chimney', 'offwidth', 'stem', 'arete',\n",
    "             'crimp', 'vertical', 'cave', 'steep', 'bouldery', 'powerful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T19:34:29.126715Z",
     "start_time": "2020-01-14T19:34:29.067098Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T19:49:43.566041Z",
     "start_time": "2020-01-14T19:49:43.535242Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_full = df_numeric.join(df_nlp)\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T19:47:23.165606Z",
     "start_time": "2020-01-14T19:47:23.146174Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_numeric.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Break descriptions into rope and boulder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Rope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T16:51:01.240404Z",
     "start_time": "2020-01-14T16:51:01.204956Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_sub = df_numeric[(df_numeric['Boulder']==0)]\n",
    "df_sub = df_sub[(df_numeric['Ice']==0)]\n",
    "df_sub = df_sub[(df_numeric['Snow']==0)]\n",
    "\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T16:51:43.371737Z",
     "start_time": "2020-01-14T16:51:43.366434Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_sub.Boulder.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T16:52:24.275152Z",
     "start_time": "2020-01-14T16:52:24.271602Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(df_sub.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T16:53:32.519370Z",
     "start_time": "2020-01-14T16:53:32.513576Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(df_nlp.loc[df_sub.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T16:54:01.641269Z",
     "start_time": "2020-01-14T16:54:01.636660Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nlp_rope =df_nlp.loc[df_sub.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T16:54:20.169674Z",
     "start_time": "2020-01-14T16:54:20.162642Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nlp_rope.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Boulder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T16:31:30.759654Z",
     "start_time": "2020-01-15T16:31:29.385302Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:07:36.736472Z",
     "start_time": "2020-01-14T18:07:36.732893Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "extra_stop = ['climb','climbing', 'crux', 'rope', 'leave', 'use', 'start', 'end',\n",
    "              'look', 'rock', 'tree', 'follow', 'continue', 'belay', 'photo', 'add', 'climber', 'route', \n",
    "              'lot', 'anchor', '...', '1', '2', '3', '4', '--', 'pitch', 'page', 'cold', 'hot', 'warm',\n",
    "              'belayer', 'fun', 'like', 'unknown', 'rap', 'left', 'right', 'wide', 'leader']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:07:37.859618Z",
     "start_time": "2020-01-14T18:07:37.857191Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for word in extra_stop:\n",
    "    stop_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:06:46.276385Z",
     "start_time": "2020-01-14T18:06:46.270105Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T16:31:34.397702Z",
     "start_time": "2020-01-15T16:31:34.393258Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(text):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = nlp(text)\n",
    "    \n",
    "#     mytokens = [word for word in mytokens if word.pos_ != \"PROPN\"]\n",
    "    \n",
    "    mytokens = [ word if word.pos_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Run the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T16:50:20.810380Z",
     "start_time": "2020-01-15T16:50:20.805679Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_nlp.loc[105714722,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T16:50:51.703422Z",
     "start_time": "2020-01-15T16:50:51.693776Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_nlp[df_nlp.isna().values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T16:40:53.500567Z",
     "start_time": "2020-01-15T16:31:45.054845Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Import TfIdfVectorizer from scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
    "tfidf = TfidfVectorizer(tokenizer=spacy_tokenizer, min_df=5, max_df=.7)\n",
    "\n",
    "\n",
    "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_matrix = tfidf.fit_transform(df_nlp['infos'])\n",
    "\n",
    "#Output the shape of tfidf_matrix\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Save it to load later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T21:36:36.712942Z",
     "start_time": "2020-01-13T21:36:36.679710Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save the trained model as a pickle string. \n",
    "from sklearn.externals import joblib \n",
    "import pickle\n",
    "tfidf_5_7 = pickle.dumps(tfidf_matrix) \n",
    "\n",
    "  \n",
    "# Save the model as a pickle in a file \n",
    "joblib.dump(tfidf_matrix, 'tfidf_5_7.pkl') \n",
    "  \n",
    "# Load the model from the file \n",
    "# tfidf_loaded = joblib.load('tfidf_5_7.pkl')  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Get original index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T15:29:30.698327Z",
     "start_time": "2020-01-14T15:29:30.693939Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#get index to iterate over\n",
    "search_range = df_in_range.orig_index\n",
    "\n",
    "# get index for target in reference to whole matrix\n",
    "nlp_target_index = int(df_in_range.orig_index[df_in_range['id']==target_id].values)\n",
    "print('target_index:',nlp_target_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T22:45:34.714406Z",
     "start_time": "2020-01-13T22:45:34.709962Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_nlp.loc[105793305]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T23:33:49.738992Z",
     "start_time": "2020-01-13T23:33:49.733309Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "######NEED TO COMBINE WITH get_recommendations so we can get average weighted score#########################\n",
    "def get_recommendations_for_nlp(idx, kernel_type):\n",
    "\n",
    "    #value to store scores and indicies\n",
    "    score_matrix = np.ndarray(shape=(len(df_in_range),2), dtype=float)\n",
    "    \n",
    "    for iter_,i in enumerate(search_range.values):\n",
    "        score = kernel_type(tfidf_matrix[idx],tfidf_matrix[i])\n",
    "        score_matrix[iter_][0] =  i        ##the index comparison corresponding to the score\n",
    "        score_matrix[iter_][1] = score     ##the score for the current index\n",
    "\n",
    "    # Sort the climbs based on the similarity scores\n",
    "    score_matrix = sorted(score_matrix, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # score_matrix\n",
    "#########################  ADD/calculate SIMilarity VALUE   ###########################\n",
    "\n",
    "    # # Get the scores of the 20 most similar climbs\n",
    "    score_matrix = score_matrix[1:20]\n",
    "\n",
    "    # # Get the climb indices (& cast to ints)\n",
    "    climb_indices = [int(i[0]) for i in score_matrix]\n",
    "    \n",
    "    # Return the top 20 most similar climbs\n",
    "    return df_numeric.iloc[climb_indices,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T23:34:33.578189Z",
     "start_time": "2020-01-13T23:34:12.616040Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rec = get_recommendations_for_nlp(nlp_target_index, cosine_similarity)\n",
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T15:24:00.009521Z",
     "start_time": "2020-01-14T15:23:59.964685Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_nlp.loc[rec.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:07:45.140285Z",
     "start_time": "2020-01-14T18:07:45.137984Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:07:45.641396Z",
     "start_time": "2020-01-14T18:07:45.638002Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(tokenizer=spacy_tokenizer, max_df=0.90, min_df=5, stop_words='english', ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:08:06.432008Z",
     "start_time": "2020-01-14T18:07:46.019752Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dtm = cv.fit_transform(nlp_rope['info'].sample(n=1000, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:08:06.757781Z",
     "start_time": "2020-01-14T18:08:06.755456Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:08:07.089358Z",
     "start_time": "2020-01-14T18:08:07.085587Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Build LDA Model\n",
    "lda_model = LatentDirichletAllocation(n_components=10,               # Number of topics\n",
    "                                      max_iter=20,               # Max learning iterations\n",
    "                                      learning_method='online',   \n",
    "                                      random_state=100,          # Random state\n",
    "                                      batch_size=32,            # n docs in each learning iter\n",
    "                                      evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
    "                                      n_jobs = -1,               # Use all available CPUs\n",
    "                                     )\n",
    "\n",
    "print(lda_model)  # Model attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:08:16.398220Z",
     "start_time": "2020-01-14T18:08:07.409388Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This can take awhile, we're dealing with a large amount of documents!\n",
    "\n",
    "lda_output = lda_model.fit_transform(dtm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Diagnose model performance with perplexity and log-likelihood\n",
    "A model with higher log-likelihood and lower perplexity (exp(-1. * log-likelihood per word)) is considered to be good. Let’s check for our model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:08:16.580319Z",
     "start_time": "2020-01-14T18:08:16.400239Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", lda_model.score(dtm))\n",
    "\n",
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", lda_model.perplexity(dtm))\n",
    "\n",
    "# See model parameters\n",
    "print(lda_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T16:21:29.674277Z",
     "start_time": "2020-01-14T16:21:29.664515Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:08:17.193851Z",
     "start_time": "2020-01-14T18:08:17.190761Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(lda_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:08:17.509158Z",
     "start_time": "2020-01-14T18:08:17.507055Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "single_topic = lda_model.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:08:17.841038Z",
     "start_time": "2020-01-14T18:08:17.838450Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_word_indices = single_topic.argsort()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:08:18.185324Z",
     "start_time": "2020-01-14T18:08:18.176400Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for index in top_word_indices:\n",
    "    print(cv.get_feature_names()[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Top words for all groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:16:12.007378Z",
     "start_time": "2020-01-14T18:16:11.843345Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for index,topic in enumerate(lda_model.components_):\n",
    "    print(f'THE TOP 15 WORDS FOR TOPIC #{index}')\n",
    "    print([cv.get_feature_names()[i] for i in topic.argsort()[-30:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T17:31:50.300746Z",
     "start_time": "2020-01-14T17:31:50.297261Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "extra_stop = ['climb','climbing', 'crux', 'rope', 'leave', 'use', 'start', 'end',\n",
    "              'look', 'rock', 'tree', 'follow', 'continue', 'belay', 'photo', 'add', 'climber', 'route', \n",
    "              'lot', 'anchor', '...', '1', '2', '3', '4', '--', 'pitch', 'page', 'cold', 'hot', 'warm',\n",
    "              'belayer', 'fun', 'like', 'unknown', 'rap', 'left', 'right']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Try new reverse tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:18:48.553092Z",
     "start_time": "2020-01-14T18:18:48.549162Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "key_words = ['slab', 'traverse', 'roof', 'corner', 'ledge', 'crack', 'face','flake', 'bolt', 'finger', 'fingers'\n",
    "             'cam', 'camalot', 'hand', 'hands', 'arch', 'balancy', 'jug', 'squeeze', 'mantel', 'sustained', 'nut', \n",
    "             'gear', 'ramp', 'overhung', 'balance', 'dihedral', 'sporty', 'heady', 'pump', 'pumpy', 'technical',\n",
    "             'run out', 'mental', 'well protected', 'chimney', 'offwidth', 'stem', 'arete', 'exposed', 'exposure',\n",
    "             'crimp','crimpy', 'vertical', 'slabby', 'cave', 'steep', 'sidepull','bouldery']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:18:50.597864Z",
     "start_time": "2020-01-14T18:18:50.592592Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer_reverse(text):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = nlp(text)\n",
    "    \n",
    "#     mytokens = [word for word in mytokens if word.pos_ != \"PROPN\"]\n",
    "    \n",
    "    mytokens = [ word if word.pos_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "    \n",
    "    #grab only my key words\n",
    "    my_sub_tokens =[]\n",
    "    for word in set(mytokens):\n",
    "        if word in key_words:\n",
    "            my_sub_tokens.append(word)\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return my_sub_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:18:53.447866Z",
     "start_time": "2020-01-14T18:18:53.444791Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(tokenizer=spacy_tokenizer_reverse,  stop_words='english', ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:19:11.866458Z",
     "start_time": "2020-01-14T18:18:53.835885Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dtm = cv.fit_transform(nlp_rope['info'].sample(n=1000, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:19:12.172426Z",
     "start_time": "2020-01-14T18:19:12.170199Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:19:12.482946Z",
     "start_time": "2020-01-14T18:19:12.478894Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Build LDA Model\n",
    "lda_model = LatentDirichletAllocation(n_components=6,               # Number of topics\n",
    "                                      max_iter=20,               # Max learning iterations\n",
    "                                      learning_method='online',   \n",
    "                                      random_state=100,          # Random state\n",
    "                                      batch_size=32,            # n docs in each learning iter\n",
    "                                      evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
    "                                      n_jobs = -1,               # Use all available CPUs\n",
    "                                     )\n",
    "\n",
    "print(lda_model)  # Model attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:19:18.873542Z",
     "start_time": "2020-01-14T18:19:12.798986Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This can take awhile, we're dealing with a large amount of documents!\n",
    "\n",
    "lda_output = lda_model.fit_transform(dtm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Diagnose model performance with perplexity and log-likelihood\n",
    "A model with higher log-likelihood and lower perplexity (exp(-1. * log-likelihood per word)) is considered to be good. Let’s check for our model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:19:19.361128Z",
     "start_time": "2020-01-14T18:19:19.209154Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", lda_model.score(dtm))\n",
    "\n",
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", lda_model.perplexity(dtm))\n",
    "\n",
    "# See model parameters\n",
    "print(lda_model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Top words for all groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:24:15.582488Z",
     "start_time": "2020-01-14T18:24:15.576973Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for index,topic in enumerate(lda_model.components_):\n",
    "    print(f'THE TOP 15 WORDS FOR TOPIC #{index}')\n",
    "    print([cv.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "567px",
    "left": "1321px",
    "right": "20px",
    "top": "120px",
    "width": "338px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
